{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest \n",
    "\n",
    "Random Forest is an **ensemble learning** method that can be used both for **classification** and **regression**. At its core, it constructs a multiple of decision trees predict an output value for a given input example. \n",
    "A simple classification example might look as follows:\n",
    "\n",
    "![caption](../figures/random_forest.png)\n",
    "\n",
    "### Preliminaries: decision tree learning\n",
    "Decision trees are a popular method for various machine learning tasks. In particular,\n",
    "trees that are grown very deep tend to learn highly irregular patterns: they overfit their training sets, i.e. have low bias but very high variance. \n",
    "Random Forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance. \n",
    "This comes at the expense of a small increase in the bias and some loss of interpretability, but generally boosts the performance in the final model.\n",
    "\n",
    "### Bagging\n",
    "The training algorithm for random forests applies the general technique of bootstrap aggregating, or bagging.\n",
    "\n",
    "**Given:** \n",
    "- dataset $\\{(\\boldsymbol{x}^{(1)}, y^{(1)}), ..., (\\boldsymbol{x}^{(m)}, y^{(m)})\\}$\n",
    "- with $\\boldsymbol{x}^{(i)}$ being a $d-$dimensional vector $\\boldsymbol{x}^i = (x^{(i)}_1, ..., x^{(i)}_d)$\n",
    "- $y^{(i)}$ being a scalar target variable\n",
    "\n",
    "bagging repeatedly ($\\boldsymbol{B}$times) selects a random sample with replacement of the training set and fits trees to these samples:\n",
    "\n",
    "For $b$ in 1,..., $\\boldsymbol{B}$:\n",
    "\n",
    "1. Sample, with replacement, $n$ training examples from $X, Y$, call these $X_b, Y_b$\n",
    "2. Train classification with tree $f_b$ on $X_b, Y_b$\n",
    "\n",
    "After training, predictions for unseen samples $x'$ can be made by averaging the predictions from all the individual regression trees on $x'$:\n",
    "\n",
    "$\\boldsymbol{\\hat{f}} = \\frac{1}{B} \\sum_{i=1}^B f_b(x')$\n",
    "\n",
    "or by taking majority vote in the case of classification trees\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}